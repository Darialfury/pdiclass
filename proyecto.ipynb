{
 "metadata": {
  "name": "",
  "signature": "sha256:90cbe6831cdc641cac3bd48674d494d80445e3db9d2f0120425bd3508f80a680"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Object recognition project"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set imports\n",
      "import cv2\n",
      "import cPickle as pickle\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import os\n",
      "import scipy.io as sio\n",
      "import matplotlib.pyplot as plt\n",
      "import multiprocessing\n",
      "import random\n",
      "\n",
      "\n",
      "from multiprocessing import Pool\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn import svm\n",
      "\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Functions to use\n",
      "\n",
      "# get all the lines of txt file and save them in a list\n",
      "def get_items_txt(txt_name):\n",
      "    lines_txt = open(txt_name, 'r')\n",
      "    list_text = []\n",
      "    for line in lines_txt:\n",
      "        newline = line.split('\\n')[0]\n",
      "        list_text.append(newline)\n",
      "    return list_text\n",
      "\n",
      "#save and object\n",
      "def save_object(obj, filename):\n",
      "    with open(filename, 'wb') as output:\n",
      "        pickle.dump(obj, output, -1)\n",
      "\n",
      "#load an object\n",
      "def load_object(filename):\n",
      "    with open(filename, 'rb') as input:\n",
      "        obj = pickle.load(input)\n",
      "    return obj\n",
      "\n",
      "def feature_quantization((file_mat, path, kmeans_object)):\n",
      "    folder = file_mat.split('/')[2]\n",
      "    name = file_mat.split('/')[3]\n",
      "    path_fq = path + folder + '/'\n",
      "    if not os.path.exists(path_fq):\n",
      "        os.makedirs(path_fq)\n",
      "    filename = path_fq + 'feature_' + name\n",
      "    var = sio.loadmat(file_mat)\n",
      "    array_to_stack = var['s_desc']\n",
      "    features = kmeans_object.predict(array_to_stack)\n",
      "    visual_words, _ = np.histogram(features, bins = k_clusters, range=(0, k_clusters -1), normed = True)\n",
      "    sio.savemat(filename, {'bow': visual_words})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Features extraction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section compute sift descriptor with each image of the dataset. For each image exists a descriptor in a folder called \"images_sift\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Creating path for storing sift features\n",
      "scale =300\n",
      "newpath = r'./images_sift_' + str(scale) + '/'\n",
      "scale='original'\n",
      "if not os.path.exists(newpath): os.makedirs(newpath)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# save in a list all folders of the dataset\n",
      "path_dataset = './resize_images_dataset_300/'\n",
      "lstring_folders = os.listdir(path_dataset)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#feature extraction of all images\n",
      "\n",
      "#search for each folder of the dataset\n",
      "for folder in lstring_folders:\n",
      "    path_folder = path_dataset + folder + '/'\n",
      "    list_images = os.listdir(path_folder)\n",
      "    list_images.sort()\n",
      "    path2_folder = newpath + folder\n",
      "    if not os.path.exists(path2_folder):\n",
      "        os.makedirs(path2_folder)\n",
      "        \n",
      "        # search for each image of the folder and compute sift\n",
      "        for image in list_images:\n",
      "            path_image_load = path_folder + '/' + image\n",
      "            x = cv2.imread(path_image_load)\n",
      "            y = cv2.cvtColor(x,cv2.COLOR_BGR2GRAY)\n",
      "            sift = cv2.SIFT()\n",
      "            kp, des = sift.detectAndCompute(y,None)\n",
      "\n",
      "            # If descriptor are none, don't save it\n",
      "            if des is not None:\n",
      "                x2 = str(image.split('.',1)[0])\n",
      "                path2 = path2_folder + '/' + x2 + '.mat'\n",
      "                sio.savemat(path2, {'s_desc': des})\n",
      "    else:\n",
      "        print 'folder ' + str(folder) + ' already exists'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Clustering with K-means"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section compute K-means with a specified k"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k_clusters = 200         # number of groups to cluster all sift features\n",
      "percentage_test = 0.30    # Test data fraction for the system\n",
      "flag = True\n",
      "min_samples =  32\n",
      "samples_train = np.ceil(min_samples*(1 - percentage_test))\n",
      "\n",
      "lstring_folders = os.listdir(path_dataset)\n",
      "\n",
      "experiment_folder = './experiment_' + str(int(percentage_test*100))+ '_c' + str(k_clusters) + '_scale_' + str(scale)\n",
      "path_codebook = experiment_folder + '/code_book.pkl'\n",
      "path_files_train = experiment_folder + '/path_files_train.txt'\n",
      "path_files_test = experiment_folder + '/path_files_test.txt'\n",
      "count_train = 0.0\n",
      "\n",
      "if not os.path.exists(experiment_folder):\n",
      "    os.makedirs(experiment_folder)\n",
      "else:\n",
      "    print 'folder ==> ' + str(experiment_folder) + ' already exists'\n",
      "files_training = []\n",
      "files_test = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "folder ==> ./experiment_30_c200_scale_original already exists\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#split data for training and testing\n",
      "for folder in lstring_folders:\n",
      "    if folder != 'BACKGROUND_Google':\n",
      "        path_folder = newpath + folder + '/'\n",
      "        list_descriptors = os.listdir(path_folder)\n",
      "\n",
      "        # list all files of the class  \n",
      "        files_in_class = []\n",
      "        for descriptor_file in list_descriptors:\n",
      "            path_descriptor_class = path_folder + descriptor_file\n",
      "            files_in_class.append(path_descriptor_class)\n",
      "\n",
      "        #split files of the class\n",
      "        a_train, a_test = train_test_split(files_in_class, train_size = int(samples_train))\n",
      "        files_training.append(a_train)\n",
      "        files_test.append(a_test)\n",
      "    else:\n",
      "        path_folder = newpath + folder + '/'\n",
      "        list_descriptors = os.listdir(path_folder)\n",
      "\n",
      "        # list all files of the class  \n",
      "        files_in_class = []\n",
      "        for descriptor_file in list_descriptors:\n",
      "            path_descriptor_class = path_folder + descriptor_file\n",
      "            files_in_class.append(path_descriptor_class)\n",
      "        files_test.append(files_in_class)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save list of files for training and testing\n",
      "if not os.path.isfile(path_files_train):\n",
      "    thefile = open(path_files_train, 'w')\n",
      "    for classe in files_training:\n",
      "        for file_mat in classe:\n",
      "            count_train += 1.0\n",
      "            thefile.write(\"%s\\n\" % file_mat)\n",
      "    thefile.close()\n",
      "\n",
      "    thefile = open(path_files_test, 'w')\n",
      "    for classe in files_test:\n",
      "        for file_mat in classe:\n",
      "            thefile.write(\"%s\\n\" % file_mat)\n",
      "    thefile.close()\n",
      "else:\n",
      "    print 'list of files created'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#compute codebook\n",
      "max_samples = 7900;\n",
      "if not os.path.isfile(path_codebook):\n",
      "    progress = 0.0\n",
      "    index = 0\n",
      "    path_features_to_codebook =  experiment_folder + '/k_groups'\n",
      "    previous_centers = np.empty(shape=[0,128])\n",
      "    list_sift = np.empty(shape=[0,128])\n",
      "\n",
      "    # search for each descriptor of the folder and stack it \n",
      "    for classes in files_training:\n",
      "        temp_sift = np.empty(shape=[0,128])\n",
      "        for descriptor_file in classes:\n",
      "            path_descriptor_load = descriptor_file\n",
      "            #print path_descriptor_load\n",
      "            var = sio.loadmat(path_descriptor_load)\n",
      "            array_to_stack = var['s_desc']\n",
      "            #print array_to_stack\n",
      "            temp_sift = np.vstack([temp_sift, array_to_stack])\n",
      "            progress += 1.0\n",
      "        rows, _ = temp_sift.shape\n",
      "        if max_samples < rows:\n",
      "            definitive_sift = random.sample(temp_sift,max_samples)\n",
      "        else:\n",
      "            definitive_sift = temp_sift\n",
      "        index += 1\n",
      "        list_sift = np.vstack([list_sift, definitive_sift])\n",
      "        print 'stacking...  ' + str(index)+ '  percentage: ' + str((float(progress/count_train))*100) + '%'\n",
      "    k_means = KMeans(init = 'k-means++', n_clusters = k_clusters, n_jobs = -1, n_init = 2, max_iter = 110)\n",
      "    k_means.fit(list_sift)\n",
      "    codebook = k_means\n",
      "    save_object(codebook, path_codebook)\n",
      "    print 'codebook created'\n",
      "else:\n",
      "    print 'Skipping... codebook computation'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "stacking...  1  percentage: 0.990099009901%\n",
        "stacking...  2  percentage: 1.9801980198%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  3  percentage: 2.9702970297%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  4  percentage: 3.9603960396%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  5  percentage: 4.9504950495%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  6  percentage: 5.94059405941%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  7  percentage: 6.93069306931%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  8  percentage: 7.92079207921%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  9  percentage: 8.91089108911%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  10  percentage: 9.90099009901%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  11  percentage: 10.8910891089%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  12  percentage: 11.8811881188%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  13  percentage: 12.8712871287%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  14  percentage: 13.8613861386%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  15  percentage: 14.8514851485%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  16  percentage: 15.8415841584%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  17  percentage: 16.8316831683%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  18  percentage: 17.8217821782%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  19  percentage: 18.8118811881%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  20  percentage: 19.801980198%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  21  percentage: 20.7920792079%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  22  percentage: 21.7821782178%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  23  percentage: 22.7722772277%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  24  percentage: 23.7623762376%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  25  percentage: 24.7524752475%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  26  percentage: 25.7425742574%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  27  percentage: 26.7326732673%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  28  percentage: 27.7227722772%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  29  percentage: 28.7128712871%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  30  percentage: 29.702970297%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  31  percentage: 30.6930693069%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  32  percentage: 31.6831683168%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  33  percentage: 32.6732673267%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  34  percentage: 33.6633663366%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  35  percentage: 34.6534653465%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  36  percentage: 35.6435643564%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  37  percentage: 36.6336633663%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  38  percentage: 37.6237623762%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  39  percentage: 38.6138613861%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  40  percentage: 39.603960396%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  41  percentage: 40.5940594059%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  42  percentage: 41.5841584158%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  43  percentage: 42.5742574257%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  44  percentage: 43.5643564356%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  45  percentage: 44.5544554455%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  46  percentage: 45.5445544554%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  47  percentage: 46.5346534653%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  48  percentage: 47.5247524752%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  49  percentage: 48.5148514851%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  50  percentage: 49.504950495%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  51  percentage: 50.495049505%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  52  percentage: 51.4851485149%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  53  percentage: 52.4752475248%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  54  percentage: 53.4653465347%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  55  percentage: 54.4554455446%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  56  percentage: 55.4455445545%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  57  percentage: 56.4356435644%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  58  percentage: 57.4257425743%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  59  percentage: 58.4158415842%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  60  percentage: 59.4059405941%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  61  percentage: 60.396039604%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  62  percentage: 61.3861386139%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  63  percentage: 62.3762376238%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  64  percentage: 63.3663366337%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  65  percentage: 64.3564356436%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  66  percentage: 65.3465346535%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  67  percentage: 66.3366336634%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  68  percentage: 67.3267326733%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  69  percentage: 68.3168316832%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  70  percentage: 69.3069306931%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  71  percentage: 70.297029703%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  72  percentage: 71.2871287129%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  73  percentage: 72.2772277228%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  74  percentage: 73.2673267327%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  75  percentage: 74.2574257426%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  76  percentage: 75.2475247525%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  77  percentage: 76.2376237624%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  78  percentage: 77.2277227723%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  79  percentage: 78.2178217822%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  80  percentage: 79.2079207921%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  81  percentage: 80.198019802%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  82  percentage: 81.1881188119%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  83  percentage: 82.1782178218%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  84  percentage: 83.1683168317%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  85  percentage: 84.1584158416%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  86  percentage: 85.1485148515%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  87  percentage: 86.1386138614%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  88  percentage: 87.1287128713%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  89  percentage: 88.1188118812%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  90  percentage: 89.1089108911%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  91  percentage: 90.099009901%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  92  percentage: 91.0891089109%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  93  percentage: 92.0792079208%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  94  percentage: 93.0693069307%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  95  percentage: 94.0594059406%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  96  percentage: 95.0495049505%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  97  percentage: 96.0396039604%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  98  percentage: 97.0297029703%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  99  percentage: 98.0198019802%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  100  percentage: 99.0099009901%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  101  percentage: 100.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "codebook created\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Feature quantization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section shows the quantization of features. First we load the codebook calculated from SIFT features and later, we quantize using it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# initialize parallelism\n",
      "pool = Pool(4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create path for features quantized\n",
      "path_folder_features_train = experiment_folder + '/features_train/'\n",
      "path_folder_features_test = experiment_folder + '/features_test/'\n",
      "\n",
      "# load codebook\n",
      "k_means = load_object(path_codebook)\n",
      "print k_means.cluster_centers_.shape\n",
      "\n",
      "if not os.path.exists(path_folder_features_train):\n",
      "    os.makedirs(path_folder_features_train)\n",
      "\n",
      "    # load data training and quantize features\n",
      "    list_text = get_items_txt(path_files_train)\n",
      "    list_replicate = [path_folder_features_train]*(len(list_text))\n",
      "    list_kmeans = [k_means]*(len(list_text))\n",
      "    list_to_use = zip(list_text, list_replicate, list_kmeans)\n",
      "    pool.map(feature_quantization, list_to_use)\n",
      "else:\n",
      "    print 'folder ==> ' + str(path_folder_features_train) + ' already exists  skipping feature quantization training...'\n",
      "    \n",
      "if not os.path.exists(path_folder_features_test):\n",
      "    os.makedirs(path_folder_features_test)\n",
      "    \n",
      "    # load data testing and quantize features\n",
      "    list_text = get_items_txt(path_files_test)\n",
      "    list_replicate = [path_folder_features_test]*(len(list_text))\n",
      "    list_kmeans = [k_means]*(len(list_text))\n",
      "    list_to_use = zip(list_text, list_replicate, list_kmeans)\n",
      "    pool.map(feature_quantization, list_to_use)    \n",
      "else:\n",
      "    print 'folder ==> ' + str(path_folder_features_test) + ' already exists skipping feature quantization testing...'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(300, 128)\n",
        "folder ==> ./experiment_30_c300_scale_300/features_train/ already exists  skipping feature quantization training...\n",
        "folder ==> ./experiment_30_c300_scale_300/features_test/ already exists skipping feature quantization testing...\n"
       ]
      }
     ],
     "prompt_number": 199
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# stack all training samples in one variable\n",
      "\n",
      "path_folder_features_train = experiment_folder + '/features_train/'\n",
      "path_folder_features_test = experiment_folder + '/features_test/'\n",
      "classes = os.listdir(path_folder_features_train)\n",
      "features_train = np.empty(shape=[0,k_clusters])\n",
      "count_label = 1\n",
      "labels_train = []\n",
      "labels_test = []\n",
      "\n",
      "print 'Loading features... '\n",
      "for category in classes:\n",
      "    path_category = path_folder_features_train + category + '/'\n",
      "    all_files = os.listdir(path_category)\n",
      "    for histogram_name in all_files:\n",
      "        path_to_load = path_category + histogram_name\n",
      "        var = sio.loadmat(path_to_load)\n",
      "        array_to_stack = var['bow']\n",
      "        features_train = np.vstack([features_train, array_to_stack])\n",
      "        labels_train.append(count_label)\n",
      "    count_label += 1\n",
      "\n",
      "'''\n",
      "path_category = path_folder_features_test + 'BACKGROUND_Google' + '/'\n",
      "all_files = os.listdir(path_category)\n",
      "for histogram_name in all_files:\n",
      "    path_to_load = path_category + histogram_name\n",
      "    var = sio.loadmat(path_to_load)\n",
      "    array_to_stack = var['bow']\n",
      "    features_train = np.vstack([features_train, array_to_stack])\n",
      "    labels_train.append(count_label)\n",
      "'''\n",
      "# stack all testing samples in one variable\n",
      "features_test = np.empty(shape=[0,k_clusters])\n",
      "count_label = 1\n",
      "for category in classes:\n",
      "    path_category = path_folder_features_test + category + '/'\n",
      "    all_files = os.listdir(path_category)\n",
      "    for histogram_name in all_files:\n",
      "        path_to_load = path_category + histogram_name\n",
      "        var = sio.loadmat(path_to_load)\n",
      "        array_to_stack = var['bow']\n",
      "        features_test = np.vstack([features_test, array_to_stack])\n",
      "        labels_test.append(count_label)\n",
      "    count_label += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading features... \n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flag_classifier = False\n",
      "number_limit = max(labels_train)+1\n",
      "quantity_class = []\n",
      "test_labels = []\n",
      "#Training on svm classifier\n",
      "print 'Training... '\n",
      "\n",
      "if flag_classifier:\n",
      "    list_clasifier = []\n",
      "    print number_limit\n",
      "    for index_class in range(0,number_limit):\n",
      "        labels = []\n",
      "        for item in labels_train:\n",
      "            if item != index_class:\n",
      "                labels.append(0)\n",
      "            else:\n",
      "                labels.append(1)\n",
      "        labels_nd = np.array(labels)\n",
      "        #pos = np.sum(labels_nd)\n",
      "        #total = len(labels)\n",
      "        #neg = total -pos\n",
      "        #w = (float(neg))/pos\n",
      "        #li_w = [w]*total\n",
      "        clasifier = svm.LinearSVC(penalty='l2', loss='l2', dual=False, tol=0.0001, C=0.00001, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight='auto', verbose=0, random_state=None)\n",
      "        labels_nd = np.transpose(labels_nd)\n",
      "        clasifier.fit(features_train, labels)\n",
      "        list_clasifier.append(clasifier)\n",
      "        print 'Testing... '\n",
      "    dec_test_values = np.empty(shape=[(len(labels_test))])\n",
      "    for index_class in range(0,number_limit):\n",
      "        count_class = 0\n",
      "        for item in labels_test:\n",
      "            if item != index_class:\n",
      "                test_labels.append(0)\n",
      "            else:\n",
      "                test_labels.append(1)\n",
      "                count_class += 1\n",
      "        quantity_class.append(count_class)\n",
      "        pred_label = list_clasifier[index_class].predict(features_test)\n",
      "        dec_values = list_clasifier[index_class].decision_function(features_test)\n",
      "        dec_test_values = np.vstack([dec_test_values, dec_values])\n",
      "    dec_test_values =  np.transpose(dec_test_values)\n",
      "    print dec_test_values.shape\n",
      "    pred_labels = np.argmax(dec_test_values, axis = 1)\n",
      "else:\n",
      "    pred_labels = OneVsRestClassifier(svm.LinearSVC()).fit(features_train, labels_train).predict(features_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training... \n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels_test = np.array(labels_test)\n",
      "print pred_labels.shape\n",
      "print labels_test.shape\n",
      "cm = confusion_matrix(labels_test, pred_labels)\n",
      "normalized_cm = cm.astype('float') / cm.sum(axis=1)\n",
      "\n",
      "print 'Performance1: ' + str(((np.sum(normalized_cm.diagonal()))*100/(number_limit-1))) + ' %'\n",
      "\n",
      "plt.matshow(normalized_cm)\n",
      "plt.title('Confusion matrix')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "#plt.show()\n",
      "save_name = os.path.join(experiment_folder, 'normalized_cm.png') \n",
      "plt.savefig(save_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(2651,)\n",
        "(2651,)\n",
        "Performance1: 8.06056209522 %\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAAD0CAYAAABqz8huAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f8781561b90>"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.sum(np.array([1,2,1,100,100,100])==np.array([1,100,1,2,2,2]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x, b =np.histogram(np.array([1,1,1,1,2,2]),bins = [1])\n",
      "print len(np.array([1,2,1,1]))\n",
      "print classes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\n",
        "['ant', 'lotus', 'crocodile', 'sea_horse', 'accordion', 'ewer', 'buddha', 'wild_cat', 'lobster', 'strawberry', 'gramophone', 'metronome', 'brontosaurus', 'kangaroo', 'grand_piano', 'pigeon', 'scissors', 'bass', 'trilobite', 'rhino', 'crocodile_head', 'wrench', 'windsor_chair', 'bonsai', 'chandelier', 'soccer_ball', 'octopus', 'Faces', 'chair', 'inline_skate', 'wheelchair', 'gerenuk', 'watch', 'dragonfly', 'headphone', 'dalmatian', 'llama', 'okapi', 'euphonium', 'crayfish', 'snoopy', 'cup', 'electric_guitar', 'water_lilly', 'pagoda', 'platypus', 'cougar_body', 'ibis', 'umbrella', 'binocular', 'dollar_bill', 'ferry', 'pizza', 'dolphin', 'menorah', 'mandolin', 'ketch', 'ceiling_fan', 'cougar_face', 'mayfly', 'brain', 'schooner', 'pyramid', 'crab', 'Leopards', 'camera', 'flamingo_head', 'flamingo', 'Faces_easy', 'garfield', 'lamp', 'airplanes', 'emu', 'barrel', 'joshua_tree', 'anchor', 'revolver', 'Motorbikes', 'tick', 'rooster', 'stegosaurus', 'minaret', 'helicopter', 'butterfly', 'hedgehog', 'nautilus', 'starfish', 'sunflower', 'panda', 'stop_sign', 'yin_yang', 'hawksbill', 'beaver', 'saxophone', 'cannon', 'car_side', 'elephant', 'stapler', 'scorpion', 'cellphone', 'laptop']\n"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print number_limit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "102\n"
       ]
      }
     ],
     "prompt_number": 212
    }
   ],
   "metadata": {}
  }
 ]
}