{
 "metadata": {
  "name": "",
  "signature": "sha256:b8a6829ee39ce995d3267ba05bd257cc806584e65334cbe99e170cb6d2b1da69"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Proyect object recognition"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set imports\n",
      "import cv2\n",
      "import cPickle as pickle\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import os\n",
      "import scipy.io as sio\n",
      "import matplotlib.pyplot as plt\n",
      "import multiprocessing\n",
      "import random\n",
      "\n",
      "\n",
      "from multiprocessing import Pool\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn import svm\n",
      "\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Functions to use\n",
      "\n",
      "# get all the lines of txt file and save them in a list\n",
      "def get_items_txt(txt_name):\n",
      "    lines_txt = open(txt_name, 'r')\n",
      "    list_text = []\n",
      "    for line in lines_txt:\n",
      "        newline = line.split('\\n')[0]\n",
      "        list_text.append(newline)\n",
      "    return list_text\n",
      "\n",
      "#save and object\n",
      "def save_object(obj, filename):\n",
      "    with open(filename, 'wb') as output:\n",
      "        pickle.dump(obj, output, -1)\n",
      "\n",
      "#load an object\n",
      "def load_object(filename):\n",
      "    with open(filename, 'rb') as input:\n",
      "        obj = pickle.load(input)\n",
      "    return obj\n",
      "\n",
      "def feature_quantization((file_mat, path, kmeans_object)):\n",
      "    folder = file_mat.split('/')[2]\n",
      "    name = file_mat.split('/')[3]\n",
      "    path_fq = path + folder + '/'\n",
      "    if not os.path.exists(path_fq):\n",
      "        os.makedirs(path_fq)\n",
      "    filename = path_fq + 'feature_' + name\n",
      "    var = sio.loadmat(file_mat)\n",
      "    array_to_stack = var['s_desc']\n",
      "    features = kmeans_object.predict(array_to_stack)\n",
      "    visual_words, _ = np.histogram(features, bins = k_clusters, range=(0, k_clusters -1), normed = True)\n",
      "    sio.savemat(filename, {'bow': visual_words})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Features extraction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section compute sift descriptor with each image of the dataset. For each image exists a descriptor in a folder called \"images_sift\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Creating path for storing sift features\n",
      "scale =300\n",
      "newpath = r'./images_sift_' + str(scale) + '/'\n",
      "scale='original'\n",
      "if not os.path.exists(newpath): os.makedirs(newpath)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# save in a list all folders of the dataset\n",
      "path_dataset = './resize_images_dataset_300/'\n",
      "lstring_folders = os.listdir(path_dataset)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#feature extraction of all images\n",
      "\n",
      "#search for each folder of the dataset\n",
      "for folder in lstring_folders:\n",
      "    path_folder = path_dataset + folder + '/'\n",
      "    list_images = os.listdir(path_folder)\n",
      "    list_images.sort()\n",
      "    path2_folder = newpath + folder\n",
      "    if not os.path.exists(path2_folder):\n",
      "        os.makedirs(path2_folder)\n",
      "        \n",
      "        # search for each image of the folder and compute sift\n",
      "        for image in list_images:\n",
      "            path_image_load = path_folder + '/' + image\n",
      "            x = cv2.imread(path_image_load)\n",
      "            y = cv2.cvtColor(x,cv2.COLOR_BGR2GRAY)\n",
      "            sift = cv2.SIFT()\n",
      "            kp, des = sift.detectAndCompute(y,None)\n",
      "\n",
      "            # If descriptor are none, don't save it\n",
      "            if des is not None:\n",
      "                x2 = str(image.split('.',1)[0])\n",
      "                path2 = path2_folder + '/' + x2 + '.mat'\n",
      "                sio.savemat(path2, {'s_desc': des})\n",
      "    else:\n",
      "        print 'folder ' + str(folder) + ' already exists'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Clustering with K-means"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section compute K-means with a specified k"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k_clusters = 200         # number of groups to cluster all sift features\n",
      "percentage_test = 0.30    # Test data fraction for the system\n",
      "flag = True\n",
      "min_samples =  32\n",
      "samples_train = np.ceil(min_samples*(1 - percentage_test))\n",
      "\n",
      "lstring_folders = os.listdir(path_dataset)\n",
      "\n",
      "experiment_folder = './experiment_' + str(int(percentage_test*100))+ '_c' + str(k_clusters) + '_scale_' + str(scale)\n",
      "path_codebook = experiment_folder + '/code_book.pkl'\n",
      "path_files_train = experiment_folder + '/path_files_train.txt'\n",
      "path_files_test = experiment_folder + '/path_files_test.txt'\n",
      "count_train = 0.0\n",
      "\n",
      "if not os.path.exists(experiment_folder):\n",
      "    os.makedirs(experiment_folder)\n",
      "else:\n",
      "    print 'folder ==> ' + str(experiment_folder) + ' already exists'\n",
      "files_training = []\n",
      "files_test = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "folder ==> ./experiment_30_c200_scale_original already exists\n"
       ]
      }
     ],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#split data for training and testing\n",
      "for folder in lstring_folders:\n",
      "    if folder != 'BACKGROUND_Google':\n",
      "        path_folder = newpath + folder + '/'\n",
      "        list_descriptors = os.listdir(path_folder)\n",
      "\n",
      "        # list all files of the class  \n",
      "        files_in_class = []\n",
      "        for descriptor_file in list_descriptors:\n",
      "            path_descriptor_class = path_folder + descriptor_file\n",
      "            files_in_class.append(path_descriptor_class)\n",
      "\n",
      "        #split files of the class\n",
      "        a_train, a_test = train_test_split(files_in_class, train_size = int(samples_train))\n",
      "        files_training.append(a_train)\n",
      "        files_test.append(a_test)\n",
      "    else:\n",
      "        path_folder = newpath + folder + '/'\n",
      "        list_descriptors = os.listdir(path_folder)\n",
      "\n",
      "        # list all files of the class  \n",
      "        files_in_class = []\n",
      "        for descriptor_file in list_descriptors:\n",
      "            path_descriptor_class = path_folder + descriptor_file\n",
      "            files_in_class.append(path_descriptor_class)\n",
      "        files_test.append(files_in_class)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save list of files for training and testing\n",
      "if not os.path.isfile(path_files_train):\n",
      "    thefile = open(path_files_train, 'w')\n",
      "    for classe in files_training:\n",
      "        for file_mat in classe:\n",
      "            count_train += 1.0\n",
      "            thefile.write(\"%s\\n\" % file_mat)\n",
      "    thefile.close()\n",
      "\n",
      "    thefile = open(path_files_test, 'w')\n",
      "    for classe in files_test:\n",
      "        for file_mat in classe:\n",
      "            thefile.write(\"%s\\n\" % file_mat)\n",
      "    thefile.close()\n",
      "else:\n",
      "    print 'list of files created'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#compute codebook\n",
      "max_samples = 7900;\n",
      "if not os.path.isfile(path_codebook):\n",
      "    progress = 0.0\n",
      "    index = 0\n",
      "    path_features_to_codebook =  experiment_folder + '/k_groups'\n",
      "    previous_centers = np.empty(shape=[0,128])\n",
      "    list_sift = np.empty(shape=[0,128])\n",
      "\n",
      "    # search for each descriptor of the folder and stack it \n",
      "    for classes in files_training:\n",
      "        temp_sift = np.empty(shape=[0,128])\n",
      "        for descriptor_file in classes:\n",
      "            path_descriptor_load = descriptor_file\n",
      "            #print path_descriptor_load\n",
      "            var = sio.loadmat(path_descriptor_load)\n",
      "            array_to_stack = var['s_desc']\n",
      "            #print array_to_stack\n",
      "            temp_sift = np.vstack([temp_sift, array_to_stack])\n",
      "            progress += 1.0\n",
      "        rows, _ = temp_sift.shape\n",
      "        if max_samples < rows:\n",
      "            definitive_sift = random.sample(temp_sift,max_samples)\n",
      "        else:\n",
      "            definitive_sift = temp_sift\n",
      "        index += 1\n",
      "        list_sift = np.vstack([list_sift, definitive_sift])\n",
      "        print 'stacking...  ' + str(index)+ '  percentage: ' + str((float(progress/count_train))*100) + '%'\n",
      "    k_means = KMeans(init = 'k-means++', n_clusters = k_clusters, n_jobs = -1, n_init = 2, max_iter = 110)\n",
      "    k_means.fit(list_sift)\n",
      "    codebook = k_means\n",
      "    save_object(codebook, path_codebook)\n",
      "    print 'codebook created'\n",
      "else:\n",
      "    print 'Skipping... codebook computation'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "stacking...  1  percentage: 0.990099009901%\n",
        "stacking...  2  percentage: 1.9801980198%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  3  percentage: 2.9702970297%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  4  percentage: 3.9603960396%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  5  percentage: 4.9504950495%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  6  percentage: 5.94059405941%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  7  percentage: 6.93069306931%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  8  percentage: 7.92079207921%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  9  percentage: 8.91089108911%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  10  percentage: 9.90099009901%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  11  percentage: 10.8910891089%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  12  percentage: 11.8811881188%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  13  percentage: 12.8712871287%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  14  percentage: 13.8613861386%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  15  percentage: 14.8514851485%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  16  percentage: 15.8415841584%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  17  percentage: 16.8316831683%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  18  percentage: 17.8217821782%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  19  percentage: 18.8118811881%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  20  percentage: 19.801980198%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  21  percentage: 20.7920792079%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  22  percentage: 21.7821782178%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  23  percentage: 22.7722772277%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  24  percentage: 23.7623762376%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  25  percentage: 24.7524752475%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  26  percentage: 25.7425742574%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  27  percentage: 26.7326732673%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  28  percentage: 27.7227722772%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  29  percentage: 28.7128712871%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  30  percentage: 29.702970297%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  31  percentage: 30.6930693069%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  32  percentage: 31.6831683168%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  33  percentage: 32.6732673267%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  34  percentage: 33.6633663366%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  35  percentage: 34.6534653465%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  36  percentage: 35.6435643564%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  37  percentage: 36.6336633663%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  38  percentage: 37.6237623762%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  39  percentage: 38.6138613861%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  40  percentage: 39.603960396%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  41  percentage: 40.5940594059%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  42  percentage: 41.5841584158%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  43  percentage: 42.5742574257%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  44  percentage: 43.5643564356%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  45  percentage: 44.5544554455%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  46  percentage: 45.5445544554%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  47  percentage: 46.5346534653%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  48  percentage: 47.5247524752%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  49  percentage: 48.5148514851%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  50  percentage: 49.504950495%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  51  percentage: 50.495049505%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  52  percentage: 51.4851485149%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  53  percentage: 52.4752475248%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  54  percentage: 53.4653465347%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  55  percentage: 54.4554455446%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  56  percentage: 55.4455445545%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  57  percentage: 56.4356435644%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  58  percentage: 57.4257425743%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  59  percentage: 58.4158415842%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  60  percentage: 59.4059405941%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  61  percentage: 60.396039604%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  62  percentage: 61.3861386139%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  63  percentage: 62.3762376238%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  64  percentage: 63.3663366337%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  65  percentage: 64.3564356436%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  66  percentage: 65.3465346535%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  67  percentage: 66.3366336634%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  68  percentage: 67.3267326733%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  69  percentage: 68.3168316832%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  70  percentage: 69.3069306931%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  71  percentage: 70.297029703%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  72  percentage: 71.2871287129%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  73  percentage: 72.2772277228%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  74  percentage: 73.2673267327%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  75  percentage: 74.2574257426%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  76  percentage: 75.2475247525%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  77  percentage: 76.2376237624%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  78  percentage: 77.2277227723%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  79  percentage: 78.2178217822%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  80  percentage: 79.2079207921%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  81  percentage: 80.198019802%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  82  percentage: 81.1881188119%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  83  percentage: 82.1782178218%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  84  percentage: 83.1683168317%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  85  percentage: 84.1584158416%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  86  percentage: 85.1485148515%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  87  percentage: 86.1386138614%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  88  percentage: 87.1287128713%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  89  percentage: 88.1188118812%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  90  percentage: 89.1089108911%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  91  percentage: 90.099009901%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  92  percentage: 91.0891089109%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  93  percentage: 92.0792079208%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  94  percentage: 93.0693069307%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  95  percentage: 94.0594059406%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  96  percentage: 95.0495049505%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  97  percentage: 96.0396039604%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  98  percentage: 97.0297029703%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  99  percentage: 98.0198019802%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  100  percentage: 99.0099009901%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  101  percentage: 100.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "codebook created\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Feature quantization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section shows the quantization of features. First we load the codebook calculated from SIFT features and later, we quantize using it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# initialize parallelism\n",
      "pool = Pool(4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create path for features quantized\n",
      "path_folder_features_train = experiment_folder + '/features_train/'\n",
      "path_folder_features_test = experiment_folder + '/features_test/'\n",
      "\n",
      "# load codebook\n",
      "k_means = load_object(path_codebook)\n",
      "print k_means.cluster_centers_.shape\n",
      "\n",
      "if not os.path.exists(path_folder_features_train):\n",
      "    os.makedirs(path_folder_features_train)\n",
      "\n",
      "    # load data training and quantize features\n",
      "    list_text = get_items_txt(path_files_train)\n",
      "    list_replicate = [path_folder_features_train]*(len(list_text))\n",
      "    list_kmeans = [k_means]*(len(list_text))\n",
      "    list_to_use = zip(list_text, list_replicate, list_kmeans)\n",
      "    pool.map(feature_quantization, list_to_use)\n",
      "else:\n",
      "    print 'folder ==> ' + str(path_folder_features_train) + ' already exists  skipping feature quantization training...'\n",
      "    \n",
      "if not os.path.exists(path_folder_features_test):\n",
      "    os.makedirs(path_folder_features_test)\n",
      "    \n",
      "    # load data testing and quantize features\n",
      "    list_text = get_items_txt(path_files_test)\n",
      "    list_replicate = [path_folder_features_test]*(len(list_text))\n",
      "    list_kmeans = [k_means]*(len(list_text))\n",
      "    list_to_use = zip(list_text, list_replicate, list_kmeans)\n",
      "    pool.map(feature_quantization, list_to_use)    \n",
      "else:\n",
      "    print 'folder ==> ' + str(path_folder_features_test) + ' already exists skipping feature quantization testing...'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(300, 128)\n",
        "folder ==> ./experiment_30_c300_scale_300/features_train/ already exists  skipping feature quantization training...\n",
        "folder ==> ./experiment_30_c300_scale_300/features_test/ already exists skipping feature quantization testing...\n"
       ]
      }
     ],
     "prompt_number": 199
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# stack all training samples in one variable\n",
      "\n",
      "path_folder_features_train = experiment_folder + '/features_train/'\n",
      "path_folder_features_test = experiment_folder + '/features_test/'\n",
      "classes = os.listdir(path_folder_features_train)\n",
      "features_train = np.empty(shape=[0,k_clusters])\n",
      "count_label = 1\n",
      "labels_train = []\n",
      "labels_test = []\n",
      "\n",
      "print 'Loading features... '\n",
      "for category in classes:\n",
      "    path_category = path_folder_features_train + category + '/'\n",
      "    all_files = os.listdir(path_category)\n",
      "    for histogram_name in all_files:\n",
      "        path_to_load = path_category + histogram_name\n",
      "        var = sio.loadmat(path_to_load)\n",
      "        array_to_stack = var['bow']\n",
      "        features_train = np.vstack([features_train, array_to_stack])\n",
      "        labels_train.append(count_label)\n",
      "    count_label += 1\n",
      "\n",
      "'''\n",
      "path_category = path_folder_features_test + 'BACKGROUND_Google' + '/'\n",
      "all_files = os.listdir(path_category)\n",
      "for histogram_name in all_files:\n",
      "    path_to_load = path_category + histogram_name\n",
      "    var = sio.loadmat(path_to_load)\n",
      "    array_to_stack = var['bow']\n",
      "    features_train = np.vstack([features_train, array_to_stack])\n",
      "    labels_train.append(count_label)\n",
      "'''\n",
      "# stack all testing samples in one variable\n",
      "features_test = np.empty(shape=[0,k_clusters])\n",
      "count_label = 1\n",
      "for category in classes:\n",
      "    path_category = path_folder_features_test + category + '/'\n",
      "    all_files = os.listdir(path_category)\n",
      "    for histogram_name in all_files:\n",
      "        path_to_load = path_category + histogram_name\n",
      "        var = sio.loadmat(path_to_load)\n",
      "        array_to_stack = var['bow']\n",
      "        features_test = np.vstack([features_test, array_to_stack])\n",
      "        labels_test.append(count_label)\n",
      "    count_label += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading features... \n"
       ]
      }
     ],
     "prompt_number": 207
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flag_classifier = False\n",
      "number_limit = max(labels_train)+1\n",
      "quantity_class = []\n",
      "if flag_classifier:\n",
      "    #Training on svm classifier\n",
      "    print 'Training... '\n",
      "    list_clasifier = []\n",
      "    \n",
      "    print number_limit\n",
      "    for index_class in range(0,number_limit):\n",
      "        labels = []\n",
      "        for item in labels_train:\n",
      "            if item != index_class:\n",
      "                labels.append(0)\n",
      "            else:\n",
      "                labels.append(1)\n",
      "        labels_nd = np.array(labels)\n",
      "        #pos = np.sum(labels_nd)\n",
      "        #total = len(labels)\n",
      "        #neg = total -pos\n",
      "        #w = (float(neg))/pos\n",
      "        #li_w = [w]*total\n",
      "        clasifier = svm.LinearSVC(penalty='l2', loss='l2', dual=False, tol=0.0001, C=0.00001, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight='auto', verbose=0, random_state=None)\n",
      "        labels_nd = np.transpose(labels_nd)\n",
      "        clasifier.fit(features_train, labels)\n",
      "        list_clasifier.append(clasifier)\n",
      "        print 'Testing... '\n",
      "    dec_test_values = np.empty(shape=[(len(labels_test))])\n",
      "    quantity_class = []\n",
      "    test_labels = []\n",
      "    for index_class in range(0,number_limit):\n",
      "        count_class = 0\n",
      "        for item in labels_test:\n",
      "            if item != index_class:\n",
      "                test_labels.append(0)\n",
      "            else:\n",
      "                test_labels.append(1)\n",
      "                count_class += 1\n",
      "        quantity_class.append(count_class)\n",
      "        pred_label = list_clasifier[index_class].predict(features_test)\n",
      "        dec_values = list_clasifier[index_class].decision_function(features_test)\n",
      "        dec_test_values = np.vstack([dec_test_values, dec_values])\n",
      "    dec_test_values =  np.transpose(dec_test_values)\n",
      "    print dec_test_values.shape\n",
      "    pred_labels = np.argmax(dec_test_values, axis = 1)\n",
      "else:\n",
      "    for index_class in range(1,number_limit):\n",
      "        count_class = 0\n",
      "        for item in labels_test:\n",
      "            if item != index_class:\n",
      "                test_labels.append(0)\n",
      "            else:\n",
      "                test_labels.append(1)\n",
      "                count_class += 1\n",
      "        quantity_class.append(count_class)\n",
      "    pred_labels = OneVsRestClassifier(svm.LinearSVC()).fit(features_train, labels_train).predict(features_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 208
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels_test = np.array(labels_test)\n",
      "\n",
      "print pred_labels.shape\n",
      "print labels_test.shape\n",
      "cm = confusion_matrix(labels_test, pred_labels)\n",
      "#for x in range(1,len(quantity_class)+1):\n",
      " #   num = len(np.where(labels_test == x)[0])\n",
      " #   normalized_cm[x-1][:] = cm[x-1][:]/(float(num))\n",
      "\n",
      "normalized_cm = cm.astype('float') / cm.sum(axis=1)\n",
      "#print 'Performance1: ' + str(((np.sum(normalized_cm.diagonal()))*100/(number_limit-1)))\n",
      "print 'Performance2: ' + str((np.sum((pred_labels == labels_test)))*100/(float(labels_test.shape[0])))\n",
      "print 'Performance3: ' + str(((100*(np.sum(cm.diagonal())))/(float(labels_test.shape[0]))))\n",
      "plt.matshow(normalized_cm)\n",
      "#plt.matshow(cm)\n",
      "plt.title('Confusion matrix')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "plt.show()\n",
      "plt.savefig('foo.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(2651,)\n",
        "(2651,)\n",
        "Performance2: 26.3674085251\n",
        "Performance3: 26.3674085251\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAAD0CAYAAABqz8huAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAgAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f2208f62290>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x7f21ce04c0d0>"
       ]
      }
     ],
     "prompt_number": 219
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "print len(np.where(np.array([1,2,1])==np.array([5]))[0])\n",
      "print number_limit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "102\n"
       ]
      }
     ],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.sum(np.array([1,2,1,100,100,100])==np.array([1,100,1,2,2,2]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x, b =np.histogram(np.array([1,1,1,1,2,2]),bins = [1])\n",
      "print len(np.array([1,2,1,1]))\n",
      "print classes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\n",
        "['ant', 'lotus', 'crocodile', 'sea_horse', 'accordion', 'ewer', 'buddha', 'wild_cat', 'lobster', 'strawberry', 'gramophone', 'metronome', 'brontosaurus', 'kangaroo', 'grand_piano', 'pigeon', 'scissors', 'bass', 'trilobite', 'rhino', 'crocodile_head', 'wrench', 'windsor_chair', 'bonsai', 'chandelier', 'soccer_ball', 'octopus', 'Faces', 'chair', 'inline_skate', 'wheelchair', 'gerenuk', 'watch', 'dragonfly', 'headphone', 'dalmatian', 'llama', 'okapi', 'euphonium', 'crayfish', 'snoopy', 'cup', 'electric_guitar', 'water_lilly', 'pagoda', 'platypus', 'cougar_body', 'ibis', 'umbrella', 'binocular', 'dollar_bill', 'ferry', 'pizza', 'dolphin', 'menorah', 'mandolin', 'ketch', 'ceiling_fan', 'cougar_face', 'mayfly', 'brain', 'schooner', 'pyramid', 'crab', 'Leopards', 'camera', 'flamingo_head', 'flamingo', 'Faces_easy', 'garfield', 'lamp', 'airplanes', 'emu', 'barrel', 'joshua_tree', 'anchor', 'revolver', 'Motorbikes', 'tick', 'rooster', 'stegosaurus', 'minaret', 'helicopter', 'butterfly', 'hedgehog', 'nautilus', 'starfish', 'sunflower', 'panda', 'stop_sign', 'yin_yang', 'hawksbill', 'beaver', 'saxophone', 'cannon', 'car_side', 'elephant', 'stapler', 'scorpion', 'cellphone', 'laptop']\n"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print number_limit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "102\n"
       ]
      }
     ],
     "prompt_number": 212
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}