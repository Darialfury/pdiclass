{
 "metadata": {
  "name": "",
  "signature": "sha256:727079c888b87c5615d510bba2cb862998d071a08f4578a7ef098a45fc353b59"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Proyect object recognition"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set imports\n",
      "import cv2\n",
      "import cPickle as pickle\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import os\n",
      "import scipy.io as sio\n",
      "import multiprocessing\n",
      "\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Functions to use\n",
      "\n",
      "#save and object\n",
      "def save_object(obj, filename):\n",
      "    with open(filename, 'wb') as output:\n",
      "        pickle.dump(obj, output, -1)\n",
      "\n",
      "#load an object\n",
      "def load_object(filename):\n",
      "    with open(filename, 'rb') as input:\n",
      "        obj = pickle.load(input)\n",
      "    return obj"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Features extraction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section compute sift descriptor with each image of the dataset. For each image exists a descriptor in a folder called \"images_sift\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Creating path for storing sift features\n",
      "newpath = r'./images_sift/'\n",
      "if not os.path.exists(newpath): os.makedirs(newpath)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# save in a list all folders of the dataset\n",
      "path_dataset = './101_ObjectCategories/'\n",
      "lstring_folders = os.listdir(path_dataset)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#feature extraction of all images\n",
      "\n",
      "#search for each folder of the dataset\n",
      "for folder in lstring_folders:\n",
      "    path_folder = path_dataset + folder + '/'\n",
      "    list_images = os.listdir(path_folder)\n",
      "    list_images.sort()\n",
      "    path2_folder = newpath + folder\n",
      "    if not os.path.exists(path2_folder):\n",
      "        os.makedirs(path2_folder)\n",
      "        \n",
      "        # search for each image of the folder and compute sift\n",
      "        for image in list_images:\n",
      "            path_image_load = path_folder + '/' + image\n",
      "            x = cv2.imread(path_image_load)\n",
      "            y = cv2.cvtColor(x,cv2.COLOR_BGR2GRAY)\n",
      "            sift = cv2.SIFT()\n",
      "            kp, des = sift.detectAndCompute(y,None)\n",
      "\n",
      "            # If descriptor are none, don't save it\n",
      "            if des is not None:\n",
      "                x2 = str(image.split('.',1)[0])\n",
      "                path2 = path2_folder + '/' + x2 + '.mat'\n",
      "                sio.savemat(path2, {'s_desc': des})\n",
      "    else:\n",
      "        print 'folder ' + str(folder) + ' already exists'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "folder ant already exists\n",
        "folder lotus already exists\n",
        "folder crocodile already exists"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "folder sea_horse already exists\n",
        "folder accordion already exists"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "folder ewer already exists\n",
        "folder buddha already exists\n",
        "folder wild_cat already exists\n",
        "folder lobster already exists\n",
        "folder strawberry already exists"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "folder gramophone already exists\n",
        "folder metronome already exists\n",
        "folder brontosaurus already exists\n",
        "folder kangaroo already exists\n",
        "folder grand_piano already exists\n",
        "folder pigeon already exists\n",
        "folder scissors already exists\n",
        "folder bass already exists\n",
        "folder trilobite already exists\n",
        "folder rhino already exists\n",
        "folder crocodile_head already exists\n",
        "folder wrench already exists\n",
        "folder windsor_chair already exists\n",
        "folder bonsai already exists\n",
        "folder chandelier already exists\n",
        "folder soccer_ball already exists\n",
        "folder octopus already exists\n",
        "folder Faces already exists\n",
        "folder chair already exists\n",
        "folder inline_skate already exists\n",
        "folder wheelchair already exists\n",
        "folder gerenuk already exists\n",
        "folder watch already exists\n",
        "folder dragonfly already exists\n",
        "folder headphone already exists\n",
        "folder dalmatian already exists\n",
        "folder llama already exists\n",
        "folder okapi already exists\n",
        "folder euphonium already exists\n",
        "folder crayfish already exists\n",
        "folder snoopy already exists\n",
        "folder cup already exists"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "folder electric_guitar already exists\n",
        "folder water_lilly already exists\n",
        "folder pagoda already exists\n",
        "folder platypus already exists\n",
        "folder cougar_body already exists\n",
        "folder ibis already exists\n",
        "folder umbrella already exists\n",
        "folder binocular already exists\n",
        "folder dollar_bill already exists\n",
        "folder ferry already exists\n",
        "folder pizza already exists\n",
        "folder dolphin already exists\n",
        "folder menorah already exists\n",
        "folder mandolin already exists\n",
        "folder ketch already exists\n",
        "folder ceiling_fan already exists\n",
        "folder cougar_face already exists\n",
        "folder mayfly already exists\n",
        "folder brain already exists\n",
        "folder schooner already exists\n",
        "folder pyramid already exists\n",
        "folder crab already exists\n",
        "folder Leopards already exists\n",
        "folder BACKGROUND_Google already exists\n",
        "folder camera already exists\n",
        "folder flamingo_head already exists\n",
        "folder flamingo already exists\n",
        "folder Faces_easy already exists\n",
        "folder garfield already exists\n",
        "folder lamp already exists\n",
        "folder airplanes already exists\n",
        "folder emu already exists\n",
        "folder barrel already exists\n",
        "folder joshua_tree already exists\n",
        "folder anchor already exists\n",
        "folder revolver already exists\n",
        "folder Motorbikes already exists\n",
        "folder tick already exists\n",
        "folder rooster already exists\n",
        "folder stegosaurus already exists\n",
        "folder minaret already exists\n",
        "folder helicopter already exists\n",
        "folder butterfly already exists\n",
        "folder hedgehog already exists\n",
        "folder nautilus already exists\n",
        "folder starfish already exists\n",
        "folder sunflower already exists\n",
        "folder panda already exists"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "folder stop_sign already exists\n",
        "folder yin_yang already exists\n",
        "folder hawksbill already exists\n",
        "folder beaver already exists\n",
        "folder saxophone already exists\n",
        "folder cannon already exists\n",
        "folder car_side already exists\n",
        "folder elephant already exists\n",
        "folder stapler already exists\n",
        "folder scorpion already exists\n",
        "folder cellphone already exists\n",
        "folder laptop already exists\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#split data for training and testing\n",
      "list_all_descriptor = []\n",
      "for folder in lstring_folders:\n",
      "    path_folder = newpath + folder + '/'\n",
      "    list_descriptors = os.listdir(path_folder)\n",
      "\n",
      "    # list all files of the class  \n",
      "    files_in_class = []\n",
      "    for descriptor_file in list_descriptors:\n",
      "        path_descriptor_class = path_folder + descriptor_file\n",
      "        files_in_class.append(path_descriptor_class)\n",
      "\n",
      "    #split files of the class\n",
      "    list_all_descriptor.append(files_in_class)\n",
      "\n",
      "#save list in a txt file\n",
      "#thefile = open(path_files_list, 'w')\n",
      "#for classe in files_training:\n",
      "#    for file_mat in classe:\n",
      "#        thefile.write(\"%s\\n\" % file_mat)\n",
      "#thefile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print des\n",
      "#print image.split('.',1)[0]\n",
      "#img = cv2.drawKeypoints(y,kp, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
      "#plt.imshow(img, cmap=plt.cm.gray, vmin=0, vmax=255)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Clustering with K-means"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section compute K-means with a specified k"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k_clusters = 100          # number of groups to cluster all sift features\n",
      "percentage_test = 0.30    # Test data fraction for the system\n",
      "flag = True\n",
      "\n",
      "path_dataset = './101_ObjectCategories/'\n",
      "lstring_folders = os.listdir(path_dataset)\n",
      "\n",
      "experiment_folder = './experiment_' + str(int(percentage_test*100))+ '_c' + str(k_clusters)\n",
      "path_codebook = experiment_folder + '/code_book.pkl'\n",
      "path_files_train = experiment_folder + '/path_files_train.txt'\n",
      "path_files_test = experiment_folder + '/path_files_test.txt'\n",
      "count_train = 0.0\n",
      "\n",
      "if not os.path.exists(experiment_folder):\n",
      "    os.makedirs(experiment_folder)\n",
      "else:\n",
      "    print 'folder ==> ' + str(experiment_folder) + ' already exists'\n",
      "files_training = []\n",
      "files_test = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#split data for training and testing\n",
      "for folder in lstring_folders:\n",
      "    if folder != 'BACKGROUND_Google':\n",
      "        path_folder = newpath + folder + '/'\n",
      "        list_descriptors = os.listdir(path_folder)\n",
      "\n",
      "        # list all files of the class  \n",
      "        files_in_class = []\n",
      "        for descriptor_file in list_descriptors:\n",
      "            path_descriptor_class = path_folder + descriptor_file\n",
      "            files_in_class.append(path_descriptor_class)\n",
      "\n",
      "        #split files of the class\n",
      "        a_train, a_test = train_test_split(files_in_class, test_size = percentage_test)\n",
      "        files_training.append(a_train)\n",
      "        files_test.append(a_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save list of files for training and testing\n",
      "thefile = open(path_files_train, 'w')\n",
      "for classe in files_training:\n",
      "    for file_mat in classe:\n",
      "        count_train += 1.0\n",
      "        thefile.write(\"%s\\n\" % file_mat)\n",
      "thefile.close()\n",
      "\n",
      "thefile = open(path_files_test, 'w')\n",
      "for classe in files_test:\n",
      "    for file_mat in classe:\n",
      "        thefile.write(\"%s\\n\" % file_mat)\n",
      "thefile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#compute codebook\n",
      "if not os.path.isfile(path_codebook):\n",
      "    progress = 0.0\n",
      "    index = 0\n",
      "    path_features_to_codebook =  experiment_folder + '/k_groups'\n",
      "    if flag:\n",
      "        previous_centers = np.empty(shape=[0,128])\n",
      "        # search for each descriptor of the folder and 1000\n",
      "        # stack it, if the sample numbers are lower than the number of clusters \n",
      "        for classes in files_training:\n",
      "            list_sift = np.empty(shape=[0,128])\n",
      "            for descriptor_file in classes:\n",
      "                path_descriptor_load = descriptor_file\n",
      "                #print path_descriptor_load\n",
      "                var = sio.loadmat(path_descriptor_load)\n",
      "                array_to_stack = var['s_desc']\n",
      "                #print array_to_stack\n",
      "                list_sift = np.vstack([list_sift, array_to_stack])\n",
      "                progress += 1.0\n",
      "            index += 1\n",
      "            print 'stacking...  ' + str(index)+ '  percentage: ' + str((float(progress/count_train))*100) + '%'\n",
      "        np.save(path_features_to_codebook, list_sift)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "stacking...  1  percentage: 0.481247925655%\n",
        "stacking...  2  percentage: 1.24460670428%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  3  percentage: 1.82542316628%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  4  percentage: 2.47261865251%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  5  percentage: 3.10321938268%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  6  percentage: 4.08230999004%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  7  percentage: 5.06140059741%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  8  percentage: 5.44307998672%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  9  percentage: 5.90773315632%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  10  percentage: 6.30600730169%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  11  percentage: 6.88682376369%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  12  percentage: 7.25190839695%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  13  percentage: 7.74975107866%"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k_means = KMeans(init = 'k-means++', n_clusters = k_clusters, n_init=10)$\n",
      "k_means.fit(list_sift)\n",
      "previous_centers = k_means.cluster_centers\n",
      "codebook = k_means\n",
      "save_object(codebook, path_codebook)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Feature quantization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section shows the quantization of features. First we load the codebook calculated from SIFT features and later, we quantize using it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create path for features quantized\n",
      "path_folder_features_train = experiment_folder + '/features_train/'\n",
      "path_folder_features_test = experiment_folder + '/features_test/'\n",
      "\n",
      "if not os.path.exists(path_folder_features_train):\n",
      "    os.makedirs(path_folder_features_train)\n",
      "else:\n",
      "    print 'folder ==> ' + str(path_folder_features_train) + ' already exists'\n",
      "    \n",
      "if not os.path.exists(path_folder_features_test):\n",
      "    os.makedirs(path_folder_features_test)\n",
      "else:\n",
      "    print 'folder ==> ' + str(path_folder_features_test) + ' already exists'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load codebook\n",
      "k_means = load_object(path_codebook)\n",
      "print k_means.cluster_centers_.shape\n",
      "\n",
      "# load data training and quantize features\n",
      "thefile = open(path_files_train, 'r')\n",
      "for file_mat in thefile:\n",
      "    print file_mat\n",
      "    file_mat = file_mat.split('\\n')[0]\n",
      "    folder = file_mat.split('/')[2]\n",
      "    name = file_mat.split('/')[3]\n",
      "    path_fq = path_folder_features_train + folder + '/'\n",
      "    if not os.path.exists(path_fq):\n",
      "        os.makedirs(path_fq)\n",
      "    else:\n",
      "        print 'folder ' + str(path_fq) + ' already exists'\n",
      "    filename = path_fq + name\n",
      "    var = sio.loadmat(file_mat)\n",
      "    array_to_stack = var['s_desc']\n",
      "    visual_words = np.histogram(array_to_stack, bins = k_clusters, range=(0, k_clusters -1))\n",
      "    sio.savemat(filename, {'bow': visual_words})\n",
      "thefile.close()\n",
      "print m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: './experiment_30_c100/code_book.pkl'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-20-7b898c9e8fe3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load codebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mk_means\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_codebook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mk_means\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# load data training and quantize features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-2-f4d2f3410efc>\u001b[0m in \u001b[0;36mload_object\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#load an object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: './experiment_30_c100/code_book.pkl'"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k_means = load_object(path_codebook)\n",
      "print k_means.cluster_centers_.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print float(12000/6026)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}