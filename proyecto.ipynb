{
 "metadata": {
  "name": "",
  "signature": "sha256:356ede249bef171cde8d01907b23aa1b0e0ed889b1c49bf0c7e46eba4a0ef0e5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Object recognition project"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set imports\n",
      "import cv2\n",
      "import cPickle as pickle\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import os\n",
      "import scipy.io as sio\n",
      "import matplotlib.pyplot as plt\n",
      "import multiprocessing\n",
      "import random\n",
      "\n",
      "\n",
      "from multiprocessing import Pool\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn import svm\n",
      "\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Functions to use\n",
      "\n",
      "# get all the lines of txt file and save them in a list\n",
      "def get_items_txt(txt_name):\n",
      "    lines_txt = open(txt_name, 'r')\n",
      "    list_text = []\n",
      "    for line in lines_txt:\n",
      "        newline = line.split('\\n')[0]\n",
      "        list_text.append(newline)\n",
      "    return list_text\n",
      "\n",
      "#save and object\n",
      "def save_object(obj, filename):\n",
      "    with open(filename, 'wb') as output:\n",
      "        pickle.dump(obj, output, -1)\n",
      "\n",
      "#load an object\n",
      "def load_object(filename):\n",
      "    with open(filename, 'rb') as input:\n",
      "        obj = pickle.load(input)\n",
      "    return obj\n",
      "\n",
      "def feature_quantization((file_mat, path, kmeans_object)):\n",
      "    folder = file_mat.split('/')[2]\n",
      "    name = file_mat.split('/')[3]\n",
      "    path_fq = path + folder + '/'\n",
      "    if not os.path.exists(path_fq):\n",
      "        os.makedirs(path_fq)\n",
      "    filename = path_fq + 'feature_' + name\n",
      "    var = sio.loadmat(file_mat)\n",
      "    array_to_stack = var['s_desc']\n",
      "    features = kmeans_object.predict(array_to_stack)\n",
      "    visual_words, _ = np.histogram(features, bins = k_clusters, range=(0, k_clusters -1), normed = True)\n",
      "    sio.savemat(filename, {'bow': visual_words})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Features extraction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section compute sift descriptor with each image of the dataset. For each image exists a descriptor in a folder called \"images_sift\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Creating path for storing sift features\n",
      "scale =300\n",
      "newpath = r'./images_sift_' + str(scale) + '/'\n",
      "#scale='original'\n",
      "if not os.path.exists(newpath): os.makedirs(newpath)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# save in a list all folders of the dataset\n",
      "path_dataset = './resize_images_dataset_300/'\n",
      "lstring_folders = os.listdir(path_dataset)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#feature extraction of all images\n",
      "\n",
      "#search for each folder of the dataset\n",
      "for folder in lstring_folders:\n",
      "    path_folder = path_dataset + folder + '/'\n",
      "    list_images = os.listdir(path_folder)\n",
      "    list_images.sort()\n",
      "    path2_folder = newpath + folder\n",
      "    if not os.path.exists(path2_folder):\n",
      "        os.makedirs(path2_folder)\n",
      "        \n",
      "        # search for each image of the folder and compute sift\n",
      "        for image in list_images:\n",
      "            path_image_load = path_folder + '/' + image\n",
      "            x = cv2.imread(path_image_load)\n",
      "            y = cv2.cvtColor(x,cv2.COLOR_BGR2GRAY)\n",
      "            sift = cv2.SIFT()\n",
      "            kp, des = sift.detectAndCompute(y,None)\n",
      "\n",
      "            # If descriptor are none, don't save it\n",
      "            if des is not None:\n",
      "                x2 = str(image.split('.',1)[0])\n",
      "                path2 = path2_folder + '/' + x2 + '.mat'\n",
      "                sio.savemat(path2, {'s_desc': des})\n",
      "    else:\n",
      "        print 'folder ' + str(folder) + ' already exists'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Clustering with K-means"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section compute K-means with a specified k"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k_clusters = 300         # number of groups to cluster all sift features\n",
      "percentage_test = 0.30    # Test data fraction for the system\n",
      "flag = True\n",
      "min_samples =  32\n",
      "samples_train = np.ceil(min_samples*(1 - percentage_test))\n",
      "\n",
      "lstring_folders = os.listdir(path_dataset)\n",
      "\n",
      "experiment_folder = './experiment_' + str(int(percentage_test*100))+ '_c' + str(k_clusters) + '_scale_' + str(scale)\n",
      "path_codebook = experiment_folder + '/code_book.pkl'\n",
      "path_files_train = experiment_folder + '/path_files_train.txt'\n",
      "path_files_test = experiment_folder + '/path_files_test.txt'\n",
      "count_train = 0.0\n",
      "\n",
      "if not os.path.exists(experiment_folder):\n",
      "    os.makedirs(experiment_folder)\n",
      "else:\n",
      "    print 'folder ==> ' + str(experiment_folder) + ' already exists'\n",
      "files_training = []\n",
      "files_test = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "folder ==> ./experiment_30_c300_scale_300 already exists\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#split data for training and testing\n",
      "for folder in lstring_folders:\n",
      "    if folder != 'BACKGROUND_Google':\n",
      "        path_folder = newpath + folder + '/'\n",
      "        list_descriptors = os.listdir(path_folder)\n",
      "\n",
      "        # list all files of the class  \n",
      "        files_in_class = []\n",
      "        for descriptor_file in list_descriptors:\n",
      "            path_descriptor_class = path_folder + descriptor_file\n",
      "            files_in_class.append(path_descriptor_class)\n",
      "\n",
      "        #split files of the class\n",
      "        a_train, a_test = train_test_split(files_in_class, train_size = int(samples_train))\n",
      "        files_training.append(a_train)\n",
      "        files_test.append(a_test)\n",
      "    else:\n",
      "        path_folder = newpath + folder + '/'\n",
      "        list_descriptors = os.listdir(path_folder)\n",
      "\n",
      "        # list all files of the class  \n",
      "        files_in_class = []\n",
      "        for descriptor_file in list_descriptors:\n",
      "            path_descriptor_class = path_folder + descriptor_file\n",
      "            files_in_class.append(path_descriptor_class)\n",
      "        files_test.append(files_in_class)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save list of files for training and testing\n",
      "if not os.path.isfile(path_files_train):\n",
      "    thefile = open(path_files_train, 'w')\n",
      "    for classe in files_training:\n",
      "        for file_mat in classe:\n",
      "            count_train += 1.0\n",
      "            thefile.write(\"%s\\n\" % file_mat)\n",
      "    thefile.close()\n",
      "\n",
      "    thefile = open(path_files_test, 'w')\n",
      "    for classe in files_test:\n",
      "        for file_mat in classe:\n",
      "            thefile.write(\"%s\\n\" % file_mat)\n",
      "    thefile.close()\n",
      "else:\n",
      "    print 'list of files created'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#compute codebook\n",
      "max_samples = 7900;\n",
      "if not os.path.isfile(path_codebook):\n",
      "    progress = 0.0\n",
      "    index = 0\n",
      "    path_features_to_codebook =  experiment_folder + '/k_groups'\n",
      "    previous_centers = np.empty(shape=[0,128])\n",
      "    list_sift = np.empty(shape=[0,128])\n",
      "\n",
      "    # search for each descriptor of the folder and stack it \n",
      "    for classes in files_training:\n",
      "        temp_sift = np.empty(shape=[0,128])\n",
      "        for descriptor_file in classes:\n",
      "            path_descriptor_load = descriptor_file\n",
      "            #print path_descriptor_load\n",
      "            var = sio.loadmat(path_descriptor_load)\n",
      "            array_to_stack = var['s_desc']\n",
      "            #print array_to_stack\n",
      "            temp_sift = np.vstack([temp_sift, array_to_stack])\n",
      "            progress += 1.0\n",
      "        rows, _ = temp_sift.shape\n",
      "        if max_samples < rows:\n",
      "            definitive_sift = random.sample(temp_sift,max_samples)\n",
      "        else:\n",
      "            definitive_sift = temp_sift\n",
      "        index += 1\n",
      "        list_sift = np.vstack([list_sift, definitive_sift])\n",
      "        print 'stacking...  ' + str(index)+ '  percentage: ' + str((float(progress/count_train))*100) + '%'\n",
      "    k_means = KMeans(init = 'k-means++', n_clusters = k_clusters, n_jobs = -1, n_init = 2, max_iter = 110)\n",
      "    k_means.fit(list_sift)\n",
      "    codebook = k_means\n",
      "    save_object(codebook, path_codebook)\n",
      "    print 'codebook created'\n",
      "else:\n",
      "    print 'Skipping... codebook computation'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "stacking...  1  percentage: 0.990099009901%\n",
        "stacking...  2  percentage: 1.9801980198%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  3  percentage: 2.9702970297%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  4  percentage: 3.9603960396%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  5  percentage: 4.9504950495%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  6  percentage: 5.94059405941%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  7  percentage: 6.93069306931%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  8  percentage: 7.92079207921%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  9  percentage: 8.91089108911%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  10  percentage: 9.90099009901%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  11  percentage: 10.8910891089%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  12  percentage: 11.8811881188%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  13  percentage: 12.8712871287%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  14  percentage: 13.8613861386%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  15  percentage: 14.8514851485%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  16  percentage: 15.8415841584%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  17  percentage: 16.8316831683%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  18  percentage: 17.8217821782%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  19  percentage: 18.8118811881%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  20  percentage: 19.801980198%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  21  percentage: 20.7920792079%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  22  percentage: 21.7821782178%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  23  percentage: 22.7722772277%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  24  percentage: 23.7623762376%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  25  percentage: 24.7524752475%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  26  percentage: 25.7425742574%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  27  percentage: 26.7326732673%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  28  percentage: 27.7227722772%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  29  percentage: 28.7128712871%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  30  percentage: 29.702970297%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  31  percentage: 30.6930693069%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  32  percentage: 31.6831683168%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  33  percentage: 32.6732673267%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  34  percentage: 33.6633663366%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  35  percentage: 34.6534653465%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  36  percentage: 35.6435643564%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  37  percentage: 36.6336633663%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  38  percentage: 37.6237623762%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  39  percentage: 38.6138613861%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  40  percentage: 39.603960396%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  41  percentage: 40.5940594059%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  42  percentage: 41.5841584158%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  43  percentage: 42.5742574257%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  44  percentage: 43.5643564356%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  45  percentage: 44.5544554455%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  46  percentage: 45.5445544554%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  47  percentage: 46.5346534653%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  48  percentage: 47.5247524752%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  49  percentage: 48.5148514851%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  50  percentage: 49.504950495%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  51  percentage: 50.495049505%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  52  percentage: 51.4851485149%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  53  percentage: 52.4752475248%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  54  percentage: 53.4653465347%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  55  percentage: 54.4554455446%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  56  percentage: 55.4455445545%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  57  percentage: 56.4356435644%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  58  percentage: 57.4257425743%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  59  percentage: 58.4158415842%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  60  percentage: 59.4059405941%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  61  percentage: 60.396039604%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  62  percentage: 61.3861386139%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  63  percentage: 62.3762376238%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  64  percentage: 63.3663366337%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  65  percentage: 64.3564356436%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  66  percentage: 65.3465346535%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  67  percentage: 66.3366336634%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  68  percentage: 67.3267326733%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  69  percentage: 68.3168316832%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  70  percentage: 69.3069306931%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  71  percentage: 70.297029703%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  72  percentage: 71.2871287129%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  73  percentage: 72.2772277228%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  74  percentage: 73.2673267327%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  75  percentage: 74.2574257426%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  76  percentage: 75.2475247525%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  77  percentage: 76.2376237624%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  78  percentage: 77.2277227723%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  79  percentage: 78.2178217822%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  80  percentage: 79.2079207921%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  81  percentage: 80.198019802%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  82  percentage: 81.1881188119%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  83  percentage: 82.1782178218%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  84  percentage: 83.1683168317%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  85  percentage: 84.1584158416%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  86  percentage: 85.1485148515%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  87  percentage: 86.1386138614%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  88  percentage: 87.1287128713%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  89  percentage: 88.1188118812%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  90  percentage: 89.1089108911%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  91  percentage: 90.099009901%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  92  percentage: 91.0891089109%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  93  percentage: 92.0792079208%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  94  percentage: 93.0693069307%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  95  percentage: 94.0594059406%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  96  percentage: 95.0495049505%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  97  percentage: 96.0396039604%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  98  percentage: 97.0297029703%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  99  percentage: 98.0198019802%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  100  percentage: 99.0099009901%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stacking...  101  percentage: 100.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "codebook created\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Feature quantization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section shows the quantization of features. First we load the codebook calculated from SIFT features and later, we quantize using it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# initialize parallelism\n",
      "pool = Pool(4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create path for features quantized\n",
      "path_folder_features_train = experiment_folder + '/features_train/'\n",
      "path_folder_features_test = experiment_folder + '/features_test/'\n",
      "\n",
      "# load codebook\n",
      "k_means = load_object(path_codebook)\n",
      "print k_means.cluster_centers_.shape\n",
      "\n",
      "if not os.path.exists(path_folder_features_train):\n",
      "    os.makedirs(path_folder_features_train)\n",
      "\n",
      "    # load data training and quantize features\n",
      "    list_text = get_items_txt(path_files_train)\n",
      "    list_replicate = [path_folder_features_train]*(len(list_text))\n",
      "    list_kmeans = [k_means]*(len(list_text))\n",
      "    list_to_use = zip(list_text, list_replicate, list_kmeans)\n",
      "    pool.map(feature_quantization, list_to_use)\n",
      "else:\n",
      "    print 'folder ==> ' + str(path_folder_features_train) + ' already exists  skipping feature quantization training...'\n",
      "    \n",
      "if not os.path.exists(path_folder_features_test):\n",
      "    os.makedirs(path_folder_features_test)\n",
      "    \n",
      "    # load data testing and quantize features\n",
      "    list_text = get_items_txt(path_files_test)\n",
      "    list_replicate = [path_folder_features_test]*(len(list_text))\n",
      "    list_kmeans = [k_means]*(len(list_text))\n",
      "    list_to_use = zip(list_text, list_replicate, list_kmeans)\n",
      "    pool.map(feature_quantization, list_to_use)    \n",
      "else:\n",
      "    print 'folder ==> ' + str(path_folder_features_test) + ' already exists skipping feature quantization testing...'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(300, 128)\n",
        "folder ==> ./experiment_30_c300_scale_300/features_train/ already exists  skipping feature quantization training...\n",
        "folder ==> ./experiment_30_c300_scale_300/features_test/ already exists skipping feature quantization testing...\n"
       ]
      }
     ],
     "prompt_number": 199
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# stack all training samples in one variable\n",
      "\n",
      "path_folder_features_train = experiment_folder + '/features_train/'\n",
      "path_folder_features_test = experiment_folder + '/features_test/'\n",
      "classes = os.listdir(path_folder_features_train)\n",
      "features_train = np.empty(shape=[0,k_clusters])\n",
      "count_label = 1\n",
      "labels_train = []\n",
      "labels_test = []\n",
      "\n",
      "print 'Loading features... '\n",
      "for category in classes:\n",
      "    path_category = path_folder_features_train + category + '/'\n",
      "    all_files = os.listdir(path_category)\n",
      "    for histogram_name in all_files:\n",
      "        path_to_load = path_category + histogram_name\n",
      "        var = sio.loadmat(path_to_load)\n",
      "        array_to_stack = var['bow']\n",
      "        features_train = np.vstack([features_train, array_to_stack])\n",
      "        labels_train.append(count_label)\n",
      "    count_label += 1\n",
      "\n",
      "'''\n",
      "path_category = path_folder_features_test + 'BACKGROUND_Google' + '/'\n",
      "all_files = os.listdir(path_category)\n",
      "for histogram_name in all_files:\n",
      "    path_to_load = path_category + histogram_name\n",
      "    var = sio.loadmat(path_to_load)\n",
      "    array_to_stack = var['bow']\n",
      "    features_train = np.vstack([features_train, array_to_stack])\n",
      "    labels_train.append(count_label)\n",
      "'''\n",
      "# stack all testing samples in one variable\n",
      "features_test = np.empty(shape=[0,k_clusters])\n",
      "count_label = 1\n",
      "for category in classes:\n",
      "    path_category = path_folder_features_test + category + '/'\n",
      "    all_files = os.listdir(path_category)\n",
      "    for histogram_name in all_files:\n",
      "        path_to_load = path_category + histogram_name\n",
      "        var = sio.loadmat(path_to_load)\n",
      "        array_to_stack = var['bow']\n",
      "        features_test = np.vstack([features_test, array_to_stack])\n",
      "        labels_test.append(count_label)\n",
      "    count_label += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading features... \n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flag_classifier = True\n",
      "number_limit = max(labels_train)+1\n",
      "quantity_class = []\n",
      "test_labels = []\n",
      "#Training on svm classifier\n",
      "print 'Training... '\n",
      "\n",
      "if flag_classifier:\n",
      "    list_clasifier = []\n",
      "    print number_limit\n",
      "    for index_class in range(0,number_limit):\n",
      "        labels = []\n",
      "        for item in labels_train:\n",
      "            if item != index_class:\n",
      "                labels.append(0)\n",
      "            else:\n",
      "                labels.append(1)\n",
      "        labels_nd = np.array(labels)\n",
      "        #pos = np.sum(labels_nd)\n",
      "        #total = len(labels)\n",
      "        #neg = total -pos\n",
      "        #w = (float(neg))/pos\n",
      "        #li_w = [w]*total\n",
      "        clasifier = svm.LinearSVC(penalty='l2', loss='l2', dual=False, tol=0.0001, C=0.00001, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight='auto', verbose=0, random_state=None)\n",
      "        labels_nd = np.transpose(labels_nd)\n",
      "        clasifier.fit(features_train, labels)\n",
      "        list_clasifier.append(clasifier)\n",
      "        print 'Testing... '\n",
      "    dec_test_values = np.empty(shape=[(len(labels_test))])\n",
      "    for index_class in range(0,number_limit):\n",
      "        count_class = 0\n",
      "        for item in labels_test:\n",
      "            if item != index_class:\n",
      "                test_labels.append(0)\n",
      "            else:\n",
      "                test_labels.append(1)\n",
      "                count_class += 1\n",
      "        quantity_class.append(count_class)\n",
      "        pred_label = list_clasifier[index_class].predict(features_test)\n",
      "        dec_values = list_clasifier[index_class].decision_function(features_test)\n",
      "        dec_test_values = np.vstack([dec_test_values, dec_values])\n",
      "    dec_test_values =  np.transpose(dec_test_values)\n",
      "    print dec_test_values.shape\n",
      "    pred_labels = np.argmax(dec_test_values, axis = 1)\n",
      "else:\n",
      "    pred_labels = OneVsRestClassifier(svm.LinearSVC()).fit(features_train, labels_train).predict(features_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training... \n",
        "102\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "The number of classes has to be greater than one.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-14-2bb3579d4d85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mclasifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.00001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ovr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_scaling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mlabels_nd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_nd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mclasifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mlist_clasifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m'Testing... '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0my_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m             raise ValueError(\"The number of classes has to be greater than\"\n\u001b[0m\u001b[0;32m    677\u001b[0m                              \" one.\")\n\u001b[0;32m    678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: The number of classes has to be greater than one."
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels_test = np.array(labels_test)\n",
      "print pred_labels.shape\n",
      "print labels_test.shape\n",
      "cm = confusion_matrix(labels_test, pred_labels)\n",
      "normalized_cm = cm.astype('float') / cm.sum(axis=1)\n",
      "\n",
      "print 'Performance1: ' + str(((np.sum(normalized_cm.diagonal()))*100/(number_limit-1))) + ' %'\n",
      "\n",
      "plt.matshow(normalized_cm)\n",
      "plt.title('Confusion matrix')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "plt.show()\n",
      "plt.savefig('foo.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(6354,)\n",
        "(6354,)\n",
        "Performance1: 20.0843996193\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAAD0CAYAAABqz8huAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD3t/kU9SB/VKAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f6e5241ba50>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x7f6e524a6fd0>"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "print len(np.where(np.array([1,2,1])==np.array([5]))[0])\n",
      "print number_limit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "102\n"
       ]
      }
     ],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.sum(np.array([1,2,1,100,100,100])==np.array([1,100,1,2,2,2]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x, b =np.histogram(np.array([1,1,1,1,2,2]),bins = [1])\n",
      "print len(np.array([1,2,1,1]))\n",
      "print classes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\n",
        "['ant', 'lotus', 'crocodile', 'sea_horse', 'accordion', 'ewer', 'buddha', 'wild_cat', 'lobster', 'strawberry', 'gramophone', 'metronome', 'brontosaurus', 'kangaroo', 'grand_piano', 'pigeon', 'scissors', 'bass', 'trilobite', 'rhino', 'crocodile_head', 'wrench', 'windsor_chair', 'bonsai', 'chandelier', 'soccer_ball', 'octopus', 'Faces', 'chair', 'inline_skate', 'wheelchair', 'gerenuk', 'watch', 'dragonfly', 'headphone', 'dalmatian', 'llama', 'okapi', 'euphonium', 'crayfish', 'snoopy', 'cup', 'electric_guitar', 'water_lilly', 'pagoda', 'platypus', 'cougar_body', 'ibis', 'umbrella', 'binocular', 'dollar_bill', 'ferry', 'pizza', 'dolphin', 'menorah', 'mandolin', 'ketch', 'ceiling_fan', 'cougar_face', 'mayfly', 'brain', 'schooner', 'pyramid', 'crab', 'Leopards', 'camera', 'flamingo_head', 'flamingo', 'Faces_easy', 'garfield', 'lamp', 'airplanes', 'emu', 'barrel', 'joshua_tree', 'anchor', 'revolver', 'Motorbikes', 'tick', 'rooster', 'stegosaurus', 'minaret', 'helicopter', 'butterfly', 'hedgehog', 'nautilus', 'starfish', 'sunflower', 'panda', 'stop_sign', 'yin_yang', 'hawksbill', 'beaver', 'saxophone', 'cannon', 'car_side', 'elephant', 'stapler', 'scorpion', 'cellphone', 'laptop']\n"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print number_limit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "102\n"
       ]
      }
     ],
     "prompt_number": 212
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}